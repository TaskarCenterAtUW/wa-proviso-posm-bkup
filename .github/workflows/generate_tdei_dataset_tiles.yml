name: Export TDEI Datasets to PMTiles

on:
  schedule:
    - cron: '0 2 */2 * *' # Runs every 2 days at 2 AM UTC
  workflow_dispatch:  # Allows manual trigger

jobs:
  backup:
    runs-on: ubuntu-latest

    steps:
      - name: Set up Java 21
        uses: actions/setup-java@v3
        with:
          distribution: 'temurin'  # Use 'zulu' or 'adopt' if needed
          java-version: '21'

      - name: Verify Java Version
        run: java -version

      - name: Checkout Repository
        uses: actions/checkout@v3
    
      - name: Install Python
        uses: actions/setup-python@v4
        with:
            python-version: '3.11'
      - name: Install Dependencies
        run: |
            python -m pip install --upgrade pip
            pip install -r tdei-dataset.txt

      - name: Setup Backup File name
        run: echo "BACKUP_FILE=washington_complete.pbf" >> $GITHUB_ENV

      - name: Setup Output Folder name
        run: echo "OUTPUT_FOLDER=wa-tdei-$(date +"%Y-%m-%d")" >> $GITHUB_ENV
    
      - name: Install jq
        run: sudo apt-get install -y jq

      - name: Login to Azure
        uses: azure/login@v1
        with:
          creds: ${{ secrets.TDEI_CORE_AZURE_CREDS }}
        
      - name: Fetch , download and extract all the projects
        working-directory: ./tdei-complete-set
        env:
            TDEI_USERNAME: ${{ secrets.TDEI_USERNAME }}
            TDEI_PASSWORD: ${{ secrets.TDEI_PASSWORD }}
        run: |
            mkdir -p downloads
            python fetch_all_projects.py
            python extract_downloaded_projects.py
    
      - name: Combine all the geojson files
        working-directory: ./tdei-complete-set
        run: |
            jq '{"type": "FeatureCollection", "features": [.[] | .features[]]}' --slurp ./downloads/*/*/*.geojson > washington_output.geojson
      - name: Combine all metadata files
        working-directory: ./tdei-complete-set
        run: |
            jq '{"type": "FeatureCollection", "features": [.[] | .dataset_detail as $detail |  .dataset_detail.dataset_area.features[] | .properties.dataset_name = $detail.name | .properties.dataset_version = $detail.version]}' --slurp ./downloads/*/metadata.json > washington_dataset_boundaries.geojson
      - name: Install Tippecanoe
        run: |
          git clone https://github.com/felt/tippecanoe.git
          cd tippecanoe
          git checkout tags/2.75.1
          make -j
          sudo make install
          tippecanoe --version

      - name: Create .pmtiles using Tippecanoe
        working-directory: ./tdei-complete-set
        run: tippecanoe -z 18 -Z 8 -o washington_complete.pmtiles --drop-densest-as-needed --extend-zooms-if-still-dropping -l wa-proviso-data washington_output.geojson

      - name: Copy the created files into output folder
        run: |
          mkdir -p output
          cp tdei-complete-set/washington_output.geojson output/washington_output.geojson
          cp tdei-complete-set/washington_complete.pmtiles output/washington_complete.pmtiles
          cp tdei-complete-set/washington_dataset_boundaries.geojson output/washington_dataset_boundaries.geojson

      - name: Check Backup File
        run: ls -lh output

      - name: Upload the file to Azure Blob Storage (dated folder)
        uses: LanceMcCarthy/Action-AzureBlobUpload@v2
        with:
          source_folder: output
          connection_string: ${{ secrets.AZURE_STORAGE_CONNECTION }}
          container_name: 'waposmdbbkup'
          destination_folder: ${{ env.OUTPUT_FOLDER }}
          delete_if_exists: 'true'

      - name: Upload the file to Azure Blob Storage (latest folder)
        uses: LanceMcCarthy/Action-AzureBlobUpload@v2
        with:
          source_folder: output
          connection_string: ${{ secrets.AZURE_STORAGE_CONNECTION }}
          container_name: 'waposmdbbkup'
          destination_folder: wa-tdei-latest
          delete_if_exists: 'true'
